# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RwPmHhDfGVRpT6HukX3Ed05jI4kWYIjb

Dataset is retrieved from here: https://www.kaggle.com/datasets/reihanenamdari/mental-health-corpus

Label 1 means the comment is poisonous and the commenter have potential mental health issues, while 0 is just the opposite

# **Colab Computer Setting**

Check the memory usage
"""

!df -h

"""Check the CPU information"""

!cat /proc/cpuinfo

"""Check the memory available"""

!cat /proc/meminfo

"""Check the GPU information"""

!nvidia-smi

"""# **Loading Data To Colab**"""

from google.colab import drive
drive.mount('/content/drive')

!mkdir "/content/shared"
!mkdir "/content/shared/input"
!mkdir "/content/shared/output"

# Tim's Environment
!cd "/content/drive/MyDrive/University/Courses/COMP 4211/Project/input" && cp -r mental_health.csv "/content/shared/input"

# Vincent's Environment
# !cd "/content/drive/MyDrive/Project/input" && cp -r mental_health.csv "/content/shared/input"

drive.flush_and_unmount()

"""# **Utility**"""

import numpy as np
import pandas as pd
import tensorflow as tf
import random
import torch
import re
import nltk
import pickle
import math
import copy
import warnings
import string
import seaborn as sns
warnings.filterwarnings('ignore')

from tqdm import tqdm
from collections import Counter
from itertools import chain
from wordcloud import WordCloud
from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer
from nltk.corpus import stopwords, wordnet
from nltk.tag import pos_tag
from sklearn import metrics
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import CountVectorizer
from gensim.models import Word2Vec
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import time
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Dense, Flatten, Conv1D, MaxPooling1D
from sklearn.metrics import accuracy_score

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')

"""# **Set Seed**

(Don't set seed when running DistilBERT & XLNet parts)
"""

# def set_all_seed(SEED = 4211):
#     random.seed(SEED)
#     np.random.seed(SEED)
#     torch.manual_seed(SEED)
#     tf.random.set_seed(SEED)

# set_all_seed()

"""# **Functions for Data Preprocessing with Demo**"""

# General Testing sentences
testing_string = "Hello, we are dealing with the data preprocessing. : Enjoy! 1 2 45"
testing_list = ["Hello", ",", "we", "are", "dealing", "with", "the", "data", "preprocessing", ".", ":", "Enjoy", "!", "1", "2", "45"]

testing_tokens = ['apple', 'banana', 'cherry']
testing_corpus = {'banana': 0, 'apple': 1, 'cherry': 2, 'date': 3}

testing_token_for_corpus = ['apple', 'banana', 'cherry', 'apple', 'banana', 'apple', 'orange']

# This function turns all the words to lowercase letter
def lowercase(sentence):

    # If it is string, directly apply the lower function and return
    if isinstance(sentence, str):
        return sentence.lower()

    # If it is a list of words, loop through the words to lower then return
    if isinstance(sentence, list):
        result = []
        for word in sentence:
            result.append(word.lower())
        return result

    # Otherwise, we will pop an error
    return "Please use String or a list of words to perform this operation"

# lowercase function demo usage
print("String - Before: ", testing_string)
print("String - After: ", lowercase(testing_string), "\n")
print("List - Before: ", testing_list)
print("List - After: ", lowercase(testing_list))

# This function would tokenize the word from a paragraph
def tokenize(paragraph):
    return nltk.word_tokenize(paragraph)

# tokenize function demo usage
print("Before tokenization: ", testing_string, "\n")
print("After tokenization: ", tokenize(testing_string))

# This function is to remove the punctuations
def remove_punctuations(tokens):
    result = []
    for token in tokens:
        if token not in string.punctuation:
            result.append(token)
    return result

# remove_punctuations function demo usage
print("Before filtering punctuations: ", testing_list)
print("After filtering punctuations: ", remove_punctuations(testing_list))

# This function is to remove the numberical data
def remove_number(tokens):
    result = []
    for token in tokens:
        if not token.isdigit():
            result.append(token)
    return result

# remove_number function demo usage
print("Before filtering number: ", testing_list)
print("After filtering number: ", remove_number(testing_list))

# This function is to stem the word by SnowballStemmer
def stemming(tokens):
    result = []
    for token in tokens:
        result.append(SnowballStemmer(language = "english").stem(token))
    return result

# stemming function demo usage
print("Before stemming: ", testing_list)
print("After stemming: ", stemming(testing_list))

# Getting the POS of the word in wordnet format
def word_pos_in_wordnet(tag):
    if tag.startswith('J'):
        return wordnet.ADJ
    elif tag.startswith('V'):
        return wordnet.VERB
    elif tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

# This function is to lemmatize the word
def lemmatize(tokens):
    result = []
    for token in tokens:
        result.append(WordNetLemmatizer().lemmatize(token, word_pos_in_wordnet(pos_tag([token])[0][1])))
    return result

# lemmatize function demo usage
print("Before lemmatization: ", testing_list)
print("After lemmatization: ", lemmatize(testing_list))

# This function is to filter out the stopwords
def filter_stopwords(tokens):
    stopword_set = set(stopwords.words('english'))

    result = []
    for token in tokens:
        if token not in stopword_set:
            result.append(token)
    return result

# filter_stopwords function demo usage
print("Before filtering stopwords: ", testing_list)
print("After filtering stopwords: ", filter_stopwords(testing_list))

# This function is to form the  n_gram of word
def n_gram(tokens, n = 1):
    if n == 1:
        return tokens
    else:
        result = []
        for i in range(len(tokens) - n + 1):
            result.append(" ".join(tokens[i : n + i]))
        return result

# n_gram function demo usage
print("Bigram: ", n_gram(testing_list, n = 2))
print("Trigram: ", n_gram(testing_list, n = 3))

# This function will return the corpus which the token within the range of frequency
def corpus(tokens, min_freq = None, max_freq = None, max_size = -1):
    # Count the frequency of each token
    token_frequencies = Counter(tokens)

    # Initialize the list of valid tokens with special tokens
    valid = ["<pad>", "<unk>"]

    # If max_size is specified and both min_freq and max_frequency are not specified
    if max_size > 0 and min_freq == None and max_freq == None:
        for token, _ in token_frequencies.most_common(max_size - 2):
          valid += [token]
    else:
        # For each token and its count
        for token, count in token_frequencies.most_common():
            # If the count is within the specified frequency range, add the token to the valid list
            if (min_freq == None or count >= min_freq) and (max_freq == None or count <= max_freq):
                valid.append(token)

    # If max_corpus_size is specified and the size of valid list exceeds max_size, truncate the list
    if max_size > 0 and len(valid) > max_size:
        valid = valid[ : max_size]

    # Create a dictionary that maps each valid token to its index
    corpus = dict(zip(valid, range(len(valid))))
    return corpus

# corpus function demo usage
print("The token list is: ", testing_token_for_corpus)
print("The output corpus with minimum frequancy 2 is: ", corpus(testing_token_for_corpus, min_freq = 2), " with length = ", len(corpus(testing_token_for_corpus, min_freq = 2)))

# This function is to one-hot a list of words to form a one-hot vector with the corpus length of self define length
def onehot_vector(tokens, corpus, length = None):
    if (length is not None):
        vector = np.zeros(min(len(corpus), length), dtype = np.int64)
    else:
        vector = np.zeros(len(corpus), dtype = np.int64)

    for token in tokens:
        index = corpus.get(token, -1)
        if (index == -1 or (length is not None and index >= length)):
            continue
        else:
            vector[index] = 1

    return vector

# onehot_vector function demo usage
print("The corpus is: ", testing_corpus)
print("The tokens is: ", testing_tokens)
print("The output of one-hot", onehot_vector(testing_tokens, testing_corpus))

def index_vector(tokens, corpus, length):
    vector = np.zeros(length, dtype = np.int64)
    for i, token in enumerate(tokens):
        if i == length:
            break

        value = corpus.get(token, -1)
        if (value != -1):
            vector[i] = value
        else:
            vector[i] = 1

    return vector

# index_vector function demo usage
print("The corpus is: ", testing_corpus)
print("The tokens is: ", testing_tokens)
print("The output of index vector with length 2", index_vector(testing_tokens, testing_corpus, 2))
print("The output of index vector with length 4", index_vector(testing_tokens, testing_corpus, 4))
print("The output of index vector with length 6", index_vector(testing_tokens, testing_corpus, 6))

def plot_accuracy(title, history):
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title(title)
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'validation'], loc = 'upper left')
    plt.show()

def plot_loss(title, history):
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title(title)
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'validation'], loc = 'upper right')
    plt.show()

def visualize_confusion_matrix(matrix):
    sns.heatmap(matrix, annot = True, cbar = True, fmt = ".0f")

"""# **Data Reading and Splitting**"""

df = pd.read_csv("/content/shared/input/mental_health.csv")
# df = pd.read_csv("/content/drive/MyDrive/Project/input/mental_health.csv")
display(df)

# Splitting the data into training and testing
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.2, random_state = 4211)

train_df = pd.concat([X_train, y_train], axis=1)
test_df = pd.concat([X_test, y_test], axis=1)

# Splitting the data into training and validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 4211)

"""64% for training

16% for validation

20% for testing
"""

print("Shape of X_train:", X_train.shape)
print("Shape of X_val:", X_val.shape)
print("Shape of X_test:", X_test.shape)

print("Shape of y_train:", y_train.shape)
print("Shape of y_val:", y_val.shape)
print("Shape of y_test:", y_test.shape)

"""# **Data Distribution**

1 means considered as a comment which is poisonous with mental health issues <br>
0 means not considered.
"""

display(train_df)

print("The distribution of different labels in training dataset:\n")
train_df["label"].value_counts(sort = True, dropna = False)

print(train_df["label"].value_counts(sort = True, dropna = False).plot(kind = "barh", title = "Distribution of different labels in training dataset", color = "orange"))

display(test_df)

print("The distribution of different labels in testing dataset:\n")
test_df["label"].value_counts(sort = True, dropna = False)

print(test_df["label"].value_counts(sort = True, dropna = False).plot(kind = "barh", title = "Distribution of different labels in testing dataset", color = "cyan"))

"""Show the word frequency for each labels and plot it as graphs
(Training Dataset only)
"""

def prep_word_count(data):

    c = Counter()

    for sentence in data:
        words = tokenize(sentence)
        words = lowercase(words)
        words = remove_punctuations(words)
        words = remove_number(words)
        words = lemmatize(words)
        words = filter_stopwords(words)

        for word in words:
            c[word] += 1

    return c

"""Training dataset"""

train_0 = train_df[train_df["label"] == 0]['text'].tolist()
train_1 = train_df[train_df["label"] == 1]['text'].tolist()

"""This takes around 5 minutes to finish"""

train_0_word_freq = prep_word_count(train_0)
train_1_word_freq = prep_word_count(train_1)

train_0_top_20 = Counter(dict(train_0_word_freq.most_common(20)))
train_1_top_20 = Counter(dict(train_1_word_freq.most_common(20)))

print("Top 20 most frequently occured words (with label 0):")
print(train_0_top_20.items())
print("\n")
print("Top 20 most frequently occured words (with label 1):")
print(train_1_top_20.items())

plt.barh(list(train_0_top_20.keys()), train_0_top_20.values(), color = "red")
plt.title("Top 20 Word Frequency in Training Dataset with Label 0")
plt.show()

plt.barh(list(train_1_top_20.keys()), train_1_top_20.values(), color = "green")
plt.title("Top 20 Word Frequency in Training Dataset with Label 1")
plt.show()

"""Testing dataset"""

test_0 = test_df[test_df["label"] == 0]['text'].tolist()
test_1 = test_df[test_df["label"] == 1]['text'].tolist()

test_0_word_freq = prep_word_count(test_0)
test_1_word_freq = prep_word_count(test_1)

test_0_top_20 = Counter(dict(test_0_word_freq.most_common(20)))
test_1_top_20 = Counter(dict(test_1_word_freq.most_common(20)))

print("Top 20 most frequently occured words (with label 0):")
print(test_0_top_20.items())
print("\n")
print("Top 20 most frequently occured words (with label 1):")
print(test_1_top_20.items())

plt.barh(list(test_0_top_20.keys()), test_0_top_20.values(), color = "red")
plt.title("Top 20 Word Frequency in Testing Dataset with Label 0")
plt.show()

plt.barh(list(test_1_top_20.keys()), test_1_top_20.values(), color = "green")
plt.title("Top 20 Word Frequency in Testing Dataset with Label 1")
plt.show()

"""Generate wordcloud"""

from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

def generate_wordcloud(words, width = 1000, height = 1000, min_font_size = 5, max_words = 250, background_color = "white"):

    wordcloud_stopwords = set(STOPWORDS)
    wordcloud = WordCloud(width = width, height = height, min_font_size = min_font_size, max_words = max_words, background_color = background_color).generate(words)

    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show()

"""Training dataset"""

train_0_for_wordcloud = list(train_0_word_freq.elements())
train_0_for_wordcloud = " ".join(train_0_for_wordcloud)

generate_wordcloud(train_0_for_wordcloud)

train_1_for_wordcloud = list(train_1_word_freq.elements())
train_1_for_wordcloud = " ".join(train_1_for_wordcloud)

generate_wordcloud(train_1_for_wordcloud, background_color = "black")

"""Testing dataset"""

test_0_for_wordcloud = list(test_0_word_freq.elements())
test_0_for_wordcloud = " ".join(test_0_for_wordcloud)

generate_wordcloud(test_0_for_wordcloud)

test_1_for_wordcloud = list(test_1_word_freq.elements())
test_1_for_wordcloud = " ".join(test_1_for_wordcloud)

generate_wordcloud(test_1_for_wordcloud)

"""# **Data Pre-Processing for Naive Bayes**"""

X_train_for_first_two, X_test_for_first_two, y_train_for_first_two, y_test_for_first_two = train_test_split(df['text'], df['label'], test_size = 0.2, random_state = 4211)

vectorizer = CountVectorizer()
X_count_vector_train = vectorizer.fit_transform(X_train_for_first_two)
X_count_vector_test = vectorizer.transform(X_test_for_first_two)

print(X_count_vector_test)

"""# **Naive Bayes**"""

# Naive Bayes by CountVectorizer
starting_time = time.time()

nb_count_model = MultinomialNB(alpha = 0).fit(X_count_vector_train, y_train_for_first_two)
print("Naive Bayes Accuracy without smoothing: ", accuracy_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))
nb_conf_mat = confusion_matrix(y_true = y_test_for_first_two, y_pred = nb_count_model.predict(X_count_vector_test))
visualize_confusion_matrix(nb_conf_mat)
print("Precision:", precision_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))
print("Recall:", recall_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))
print("F1 Score:", f1_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))

# Naive Bayes by CountVectorizer
nb_count_model = MultinomialNB().fit(X_count_vector_train, y_train_for_first_two)
print("Naive Bayes Accuracy with smoothing: ", accuracy_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))
nb_conf_mat = confusion_matrix(y_true = y_test_for_first_two, y_pred = nb_count_model.predict(X_count_vector_test))
visualize_confusion_matrix(nb_conf_mat)
print("Precision:", precision_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))
print("Recall:", recall_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))
print("F1 Score:", f1_score(y_test_for_first_two, nb_count_model.predict(X_count_vector_test)))

ending_time = time.time()

print("The time usage in the Naive Bayes is ", ending_time - starting_time, " seconds")

"""# **Data Pre-Processing For below model**"""

print("Shape of X_train:", X_train.shape)
print("Shape of X_val:", X_val.shape)
print("Shape of X_test:", X_test.shape)

print("Shape of y_train:", y_train.shape)
print("Shape of y_val:", y_val.shape)
print("Shape of y_test:", y_test.shape)

# Preprocessing the data
starting_time = time.time()
X_train = [n_gram(filter_stopwords(lemmatize(remove_punctuations(remove_number(tokenize(lowercase(x))))))) for x in X_train]
X_val = [n_gram(filter_stopwords(lemmatize(remove_punctuations(remove_number(tokenize(lowercase(x))))))) for x in X_val]
ending_time = time.time()
print("Time usage = ", ending_time - starting_time)

# For evaluating the first 10 stuff in training data
for i in range(10):
    print(X_train[i])

print(y_train[:10])

"""# **One-Hot MLP Model**

# One-Hot Length = 100
"""

# Build the corpus for the one-hot vector with max length = 100
corpus_onehot = corpus([token for sublist in (X_train + X_val) for token in sublist], max_size = 100)

# Prepare one-hot vector
X_train_one_hot_vector = [onehot_vector(x, corpus_onehot) for x in X_train]
X_val_one_hot_vector = [onehot_vector(x, corpus_onehot) for x in X_val]

y_train_one_hot = pd.get_dummies(y_train)
y_val_one_hot = pd.get_dummies(y_val)

print("X_train one-hot with the first 10 stuff")
print(X_train_one_hot_vector[ : 10])

print("y_train one-hot with the first 10 stuff")
print(y_train_one_hot[ : 10])

# This function return the model of one-hot
def get_onehot_model(input_shape):

    model = Sequential()
    model.add(Flatten(input_shape = input_shape))
    model.add(Dense(16, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(8, activation='relu'))
    model.add(Dense(8, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4, activation='relu'))

    model.add(Dense(2, activation='softmax'))

    return model

# Get the details about the model
get_onehot_model(input_shape = np.array(X_train_one_hot_vector).shape[1:]).summary()

# The training of the onehot model
onehot100_model = get_onehot_model(input_shape = np.array(X_train_one_hot_vector).shape[1:])
onehot100_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
onehot100_history = onehot100_model.fit(np.array(X_train_one_hot_vector), np.array(y_train_one_hot), batch_size = 64, epochs = 10, validation_data = (np.array(X_val_one_hot_vector), np.array(y_val_one_hot)))

plot_accuracy("One-Hot MLP Model Accuracy (length = 100)", onehot100_history)
plot_loss("One-Hot MLP Model Loss (length = 100)", onehot100_history)

# Performance evaluation in testing set
X_test_one_hot = [n_gram(filter_stopwords(lemmatize(remove_punctuations(remove_number(tokenize(lowercase(x))))))) for x in test_df['text']]
X_test_one_hot = [onehot_vector(x, corpus_onehot) for x in X_test_one_hot]
y_test_one_hot = test_df['label']

# Accuracy Performance
y_predict_class = np.argmax(onehot100_model.predict(np.array(X_test_one_hot)), axis = 1)
accuracy = accuracy_score(y_test_one_hot, y_predict_class)
print("Test Accuracy: {:.2f}%".format(accuracy * 100))

# COnfusion Matrix
onehot100_conf_mat = confusion_matrix(y_true = y_test_one_hot, y_pred = y_predict_class)
visualize_confusion_matrix(onehot100_conf_mat)

# This function return the model of one-hot
# This is a more complex model for analyzing the length of encoding
def get_onehot_model(input_shape):

    model = Sequential()
    model.add(Flatten(input_shape = input_shape))
    model.add(Dense(256, activation='relu'))
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(16, activation='relu'))

    model.add(Dense(2, activation='softmax'))

    return model

# Get the details about the model
get_onehot_model(input_shape = np.array(X_train_one_hot_vector).shape[1:]).summary()

# The training of the onehot model
onehot100_model_complex = get_onehot_model(input_shape = np.array(X_train_one_hot_vector).shape[1:])
onehot100_model_complex.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
onehot100_history_complex = onehot100_model_complex.fit(np.array(X_train_one_hot_vector), np.array(y_train_one_hot), batch_size = 64, epochs = 10, validation_data = (np.array(X_val_one_hot_vector), np.array(y_val_one_hot)))

plot_accuracy("One-Hot Complex MLP Model Accuracy (length = 100)", onehot100_history_complex)
plot_loss("One-Hot Complex MLP Model Loss (length = 100)", onehot100_history_complex)

# Accuracy performance
y_predict_class = np.argmax(onehot100_model_complex.predict(np.array(X_test_one_hot)), axis = 1)
accuracy = accuracy_score(y_test_one_hot, y_predict_class)
print("Test Accuracy: {:.2f}%".format(accuracy * 100))

# Confusion Matrix
onehot100_conf_mat_complex = confusion_matrix(y_true = y_test_one_hot, y_pred = y_predict_class)
visualize_confusion_matrix(onehot100_conf_mat_complex)

"""# One-Hot Length = 1000"""

# Build the corpus for the one-hot vector with max length = 1000
corpus_onehot = corpus([token for sublist in (X_train + X_val) for token in sublist], max_size = 1000)

# Prepare one-hot vector
X_train_one_hot_vector = [onehot_vector(x, corpus_onehot) for x in X_train]
X_val_one_hot_vector = [onehot_vector(x, corpus_onehot) for x in X_val]

y_train_one_hot = pd.get_dummies(y_train)
y_val_one_hot = pd.get_dummies(y_val)

# This function return the model of one-hot
def get_onehot_model(input_shape):

    model = Sequential()
    model.add(Flatten(input_shape = input_shape))
    model.add(Dense(16, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(8, activation='relu'))
    model.add(Dense(8, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4, activation='relu'))

    model.add(Dense(2, activation='softmax'))

    return model

# Get the details about the model
get_onehot_model(input_shape = np.array(X_train_one_hot_vector).shape[1:]).summary()

# The training of the onehot model
onehot1000_model = get_onehot_model(input_shape = np.array(X_train_one_hot_vector).shape[1:])
onehot1000_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
onehot1000_history = onehot1000_model.fit(np.array(X_train_one_hot_vector), np.array(y_train_one_hot), batch_size = 64, epochs = 3, validation_data = (np.array(X_val_one_hot_vector), np.array(y_val_one_hot)))

plot_accuracy("One-Hot MLP Model Accuracy (length = 1000)", onehot1000_history)
plot_loss("One-Hot MLP Model Loss (length = 1000)", onehot1000_history)

# Performance evaluation in testing set
X_test_one_hot = [n_gram(filter_stopwords(lemmatize(remove_punctuations(remove_number(tokenize(lowercase(x))))))) for x in test_df['text']]
X_test_one_hot = [onehot_vector(x, corpus_onehot) for x in X_test_one_hot]
y_test_one_hot = test_df['label']

# Accuracy performance
y_predict_class = np.argmax(onehot1000_model.predict(np.array(X_test_one_hot)), axis = 1)
accuracy = accuracy_score(y_test_one_hot, y_predict_class)
print("Test Accuracy: {:.2f}%".format(accuracy * 100))

# Confusion Matrix
onehot1000_conf_mat = confusion_matrix(y_true = y_test_one_hot, y_pred = y_predict_class)
visualize_confusion_matrix(onehot1000_conf_mat)

"""# **Index RNN Model**"""

# Build the corpus for the index vector
corpus_index = corpus([token for sublist in (X_train + X_val) for token in sublist])

# Prepare index vactor
X_train_index_vector = [index_vector(x, corpus_index, length = 100) for x in X_train]
X_val_index_vector = [index_vector(x, corpus_index, length = 100) for x in X_val]

y_train_index_vector = pd.get_dummies(y_train)
y_val_index_vector = pd.get_dummies(y_val)

# Checking the output
count = 0
for key, value in corpus_index.items():
    print(key, value)
    count += 1
    if count == 20:
        break

# Checking the output
for i in range(10):
    print(X_train_index_vector[i])

# This function return the model of index
def get_index_model(corpus_index):

    model = Sequential()
    model.add(Embedding(input_dim = len(corpus_index), output_dim = 32))
    model.add(LSTM(16, return_sequences = True))
    model.add(Dropout(0.5))
    model.add(LSTM(8))
    model.add(Dense(2, activation='softmax'))

    return model

# Get the details about the model
get_index_model(corpus_index).summary()

# The training of the index model
index_model = get_index_model(corpus_index)
index_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
lstm_history = index_model.fit(np.array(X_train_index_vector), np.array(y_train_index_vector), batch_size = 64, epochs = 3, validation_data = (np.array(X_val_index_vector), np.array(y_val_index_vector)))

plot_accuracy("LSTM Model Accuracy", lstm_history)

plot_loss("LSTM Model Loss", lstm_history)

# Performance evaluation in testing set
X_test_index = [n_gram(filter_stopwords(lemmatize(remove_punctuations(remove_number(tokenize(lowercase(x))))))) for x in test_df['text']]
X_test_index = [index_vector(x, corpus_index, length = 100) for x in X_test_index]
y_test_index = test_df['label']

# Accuracy performance
y_predict_class = np.argmax(index_model.predict(np.array(X_test_index)), axis = 1)
accuracy = accuracy_score(y_test_index, y_predict_class)
print("Test Accuracy: {:.2f}%".format(accuracy * 100))

# Confusion Matrix
index_conf_mat = confusion_matrix(y_true = y_test_index, y_pred = y_predict_class)
visualize_confusion_matrix(index_conf_mat)

"""# **CNN Model**"""

# Build the corpus for the index vector
corpus_cnn = corpus([token for sublist in (X_train + X_val) for token in sublist])

# Prepare index vactor
X_train_cnn_vector = [index_vector(x, corpus_cnn, length = 100) for x in X_train]
X_val_cnn_vector = [index_vector(x, corpus_cnn, length = 100) for x in X_val]

y_train_cnn_vector = pd.get_dummies(y_train)
y_val_cnn_vector = pd.get_dummies(y_val)

# This function return the model of CNN
def get_cnn_model(corpus_cnn):

    model = Sequential()
    model.add(Embedding(input_dim = len(corpus_cnn), output_dim = 32, input_length = 100))
    model.add(Conv1D(filters = 16, kernel_size = 4, padding = 'same', activation = 'relu'))
    model.add(MaxPooling1D(pool_size = 2))
    model.add(Dropout(0.5))
    model.add(Conv1D(filters = 16, kernel_size = 4, padding = 'same', activation = 'relu'))
    model.add(MaxPooling1D(pool_size = 2))
    model.add(Flatten())
    model.add(Dense(4, activation = 'relu'))
    model.add(Dense(2, activation = 'softmax'))

    return model

# Get the details about the model
get_cnn_model(corpus_cnn).summary()

# The training of the index model
cnn_model = get_cnn_model(corpus_cnn)
cnn_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])
cnn_history = cnn_model.fit(np.array(X_train_cnn_vector), np.array(y_train_cnn_vector), batch_size = 64, epochs = 3, validation_data = (np.array(X_val_cnn_vector), np.array(y_val_cnn_vector)))

plot_accuracy("CNN Model Accuracy", cnn_history)

plot_loss("CNN Model Loss", cnn_history)

# Performance evaluation in testing set
X_test_cnn = [n_gram(filter_stopwords(lemmatize(remove_punctuations(remove_number(tokenize(lowercase(x))))))) for x in test_df['text']]
X_test_cnn = [index_vector(x, corpus_cnn, length = 100) for x in X_test_cnn]
y_test_cnn = test_df['label']

# Accuracy performance
y_predict_class = np.argmax(cnn_model.predict(np.array(X_test_cnn)), axis = 1)
accuracy = accuracy_score(y_test_cnn, y_predict_class)
print("Test Accuracy: {:.2f}%".format(accuracy * 100))

# Confusion Matrix
cnn_conf_mat = confusion_matrix(y_true = y_test_cnn, y_pred = y_predict_class)
visualize_confusion_matrix(cnn_conf_mat)

"""# **DistilBERT**

research paper: https://arxiv.org/pdf/1910.01108.pdf

Explicitly specify we need to use transformers package from Hugging Face with version 4.31.0 (which is more stable)
"""

!pip install transformers==4.31.0

"""import necessary libraries and packages"""

import os
from tqdm import tqdm
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from transformers import DistilBertTokenizer, TFDistilBertModel
from tokenizers import BertWordPieceTokenizer

"""initialize the seed as 4211"""

SEED = 4211

"""read the dataset"""

df = pd.read_csv("/content/shared/input/mental_health.csv")

"""Split the dataset to train, valiation and test dataset"""

# Splitting the data into training and testing
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.2, random_state = 4211)

# Splitting the data into training and validation
X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 4211)

# X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.25, random_state = 4211, shuffle = True)

"""for encoding the words with the DistilBERT tokenizers

and return the encoded words (in a numy array)
"""

def DistilBERT_encoding(sentences, tokenizer, window_size = 1, max_length = 128):

    tokenizer.enable_truncation(max_length = max_length)
    tokenizer.enable_padding(length = max_length)

    ID = []

    for i in tqdm(range(0, len(sentences), window_size)):
        window = sentences[i : i + window_size].tolist()
        encoding = tokenizer.encode_batch(window)
        ID.extend([encode_word.ids for encode_word in encoding])

    return np.array(ID)

"""configuration of number of epoches, batch size and max length"""

AUTO = tf.data.experimental.AUTOTUNE
EPOCHS = 3
BATCH_SIZE = 64
MAX_LEN = 128

"""download the vocbulary text file for the tokenizer from Hugging Face"""

!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt

"""configure the tokenizer"""

DistilBERT_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')

BertWP_tokenizer = BertWordPieceTokenizer('bert-base-uncased-vocab.txt', lowercase = True)

DistilBERT_tokenizer

BertWP_tokenizer

"""encode the train, validation and test dataset"""

x_train = DistilBERT_encoding(X_train.astype(str), BertWP_tokenizer)
x_valid = DistilBERT_encoding(X_valid.astype(str), BertWP_tokenizer)
x_test = DistilBERT_encoding(X_test.astype(str), BertWP_tokenizer)

# x_train = fast_encode(train1.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)
# x_valid = fast_encode(valid.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)
# x_test = fast_encode(test.content.astype(str), fast_tokenizer, maxlen=MAX_LEN)

# y_train = train1.toxic.values
# y_valid = valid.toxic.values

"""change the train, validate and test dataset to td.data.Dataset"""

train_dataset = (tf.data.Dataset
                 .from_tensor_slices((x_train, y_train.astype(int)))
                 .shuffle(SEED)
                 .batch(BATCH_SIZE)
                 .prefetch(AUTO))

valid_dataset = (tf.data.Dataset
                 .from_tensor_slices((x_valid, y_valid.astype(int)))
                 .shuffle(SEED)
                 .batch(BATCH_SIZE)
                 .prefetch(AUTO))

test_dataset = (tf.data.Dataset
                 .from_tensor_slices((x_test))
                 .batch(BATCH_SIZE))

"""change the test labels to int data type"""

y_test = y_test.astype(int)

"""build the DistilBERT model"""

def build_DistilBERT(transformer_layer, max_len = MAX_LEN):

    input = Input(shape = (max_len,), dtype = tf.int64, name = "input")
    trans_out = transformer_layer(input)[0]
    classify_token = trans_out[:, 0, :]
    output = Dense(1, activation = "sigmoid", name = "output")(classify_token)

    model = Model(inputs = input, outputs = output, name = "DistilBERT")
    model.compile(Adam(learning_rate = 1e-5), loss = 'binary_crossentropy', metrics = ['accuracy'])

    return model

"""get the pretrained DistilBERT model"""

# from tensorflow.distribute.Strategy import scope

# with strategy.scope():
transformer_layer = TFDistilBertModel.from_pretrained('distilbert-base-multilingual-cased')

"""check the summary of the DistilBERT model"""

DistilBERT_model = build_DistilBERT(transformer_layer)

DistilBERT_model.summary()

"""271 seconds for epoch 1

250 seconds for epoch 2

250 seconds for epoch 3

train for 3 epoches
"""

DistilBERT_history = DistilBERT_model.fit(x = train_dataset, validation_data = valid_dataset, epochs = EPOCHS, verbose = 1)

"""plotting DistilBERT model accuracy"""

plot_accuracy("DistilBERT model accuracy", DistilBERT_history)

"""plotting DistilBERT model loss"""

plot_loss("DistilBERT model loss", DistilBERT_history)

"""predict the labels on test dataset"""

DistilBERT_test_predict = DistilBERT_model.predict(test_dataset, verbose = 1)

DistilBERT_test_predict

"""treat the values greater than 0.5 as label of 1, otherwise treat as label of 0"""

DistilBERT_test_predict_label = (DistilBERT_test_predict > 0.5).astype(int).flatten()

DistilBERT_test_predict_label

y_test_true_label = y_test.to_numpy()

y_test_true_label

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

"""output the precision, recall, F1 score, accuracy and confusion matrix"""

print(classification_report(y_true = y_test_true_label, y_pred = DistilBERT_test_predict_label))
print("\n\n")
print(confusion_matrix(y_true = y_test_true_label, y_pred = DistilBERT_test_predict_label))
print("\n\n")
print('testing accuracy:', np.mean(y_test_true_label == DistilBERT_test_predict_label))

"""visualize the confusion matrix"""

DistilBERT_conf_mat = confusion_matrix(y_true = y_test_true_label, y_pred = DistilBERT_test_predict_label)
visualize_confusion_matrix(DistilBERT_conf_mat)

"""create the test dataset as tf.data.Dataset"""

test_dataset_for_evaluate = (tf.data.Dataset
                 .from_tensor_slices((x_test, y_test.astype(int)))
                 .shuffle(SEED)
                 .batch(BATCH_SIZE)
                 .prefetch(AUTO))

"""output the train, validation and test accuracy and loss"""

DistilBERT_train_score = DistilBERT_model.evaluate(train_dataset, batch_size = 1)
DistilBERT_valid_score = DistilBERT_model.evaluate(valid_dataset, batch_size = 1)
DistilBERT_test_score = DistilBERT_model.evaluate(test_dataset_for_evaluate, batch_size = 1)

print("training loss:", DistilBERT_train_score[0], "training accuracy", DistilBERT_train_score[1])
print("validation loss:", DistilBERT_valid_score[0], "validation accuracy", DistilBERT_valid_score[1])
print("testing loss:", DistilBERT_test_score[0], "testing accuracy", DistilBERT_test_score[1])

"""# **XLNet**

research paper: https://dl.acm.org/doi/pdf/10.5555/3454287.3454804

Explicitly specify we need to use transformers package from Hugging Face with version 4.31.0 (which is more stable)
"""

!pip install transformers==4.31.0

"""import the necessary packages and libraries"""

import tensorflow as tf
from transformers import TFXLNetModel, XLNetTokenizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Dense, Input, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model

"""read the dataset"""

df = pd.read_csv("/content/shared/input/mental_health.csv")

"""split the dataser into train, validation and test dataset"""

# Splitting the data into training and testing
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.2, random_state = 4211)

# Splitting the data into training and validation
X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.2, random_state = 4211)

# X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size = 0.25, random_state = 4211, shuffle = True)

"""https://huggingface.co/docs/transformers/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_encode_plus

encode the words using the tokenizer from XLNet
"""

def XLNet_encoding(sentences, tokenizer, window_size = 1, max_length = 128):

    ID = []

    for i in tqdm(range(0, len(sentences), window_size)):
        window = sentences[i : i + window_size].tolist()
        encoding = tokenizer.batch_encode_plus(window, padding = "max_length", truncation = "longest_first", max_length = max_length)
        encoding = sum(encoding["input_ids"], [])
        ID.extend([encoding])

    return np.array(ID)

"""get the pretrained XLNet tokenizer"""

XLNet_tokenizer = XLNetTokenizer.from_pretrained("xlnet-base-cased")

XLNet_tokenizer

"""use XLNet tokenizer to encode train, validate and test dataset"""

x_train = XLNet_encoding(X_train.astype(str), XLNet_tokenizer)
x_valid = XLNet_encoding(X_valid.astype(str), XLNet_tokenizer)
x_test = XLNet_encoding(X_test.astype(str), XLNet_tokenizer)

print(x_train.shape)

print(y_train.shape)

print(x_valid.shape)

print(y_valid.shape)

print(x_test.shape)

print(y_test.shape)

AUTO = tf.data.experimental.AUTOTUNE

"""set the seed as 4211"""

SEED = 4211

"""set the number of epoches, batch size and maximum length"""

EPOCHS = 3
BATCH_SIZE = 64
MAX_LEN = 128

"""convert train, validation and test dataset to tf.data.Dataset"""

train_dataset = (tf.data.Dataset
                 .from_tensor_slices((x_train, y_train.astype(int)))
                 .shuffle(SEED)
                 .batch(BATCH_SIZE)
                 .prefetch(AUTO))

valid_dataset = (tf.data.Dataset
                 .from_tensor_slices((x_valid, y_valid.astype(int)))
                 .shuffle(SEED)
                 .batch(BATCH_SIZE)
                 .prefetch(AUTO))

test_dataset = (tf.data.Dataset
                 .from_tensor_slices((x_test))
                 .batch(BATCH_SIZE))

"""convert the test labels as int data type"""

y_test = y_test.astype(int)

"""build the XLNet model"""

def build_XLNet(max_len = 128):

    input = Input(shape = (max_len,), name = "input", dtype = "int32")

    XLNet = TFXLNetModel.from_pretrained('xlnet-base-cased')
    XLNet_encode = XLNet(input)[0]

    sentence_encode = tf.squeeze(XLNet_encode[:, -1:, :], axis = 1)
    dropout = Dropout(0.05, name = "dropout")(sentence_encode)

    output = Dense(1, activation = "sigmoid", name = "output")(dropout)

    model = Model(inputs = [input], outputs = [output], name = "XLNet")

    model.compile(optimizer = Adam(learning_rate = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])

    return model

"""check the summary of the built XLNet model"""

XLNet_model = build_XLNet()

XLNet_model.summary()

"""Epoch 1 takes 685 seconds

Epoch 2 takes 647 seconds

Epoch 3 takes 647 seconds
"""

# XLNet_history = XLNet_model.fit(x = train_dataset, validation_data = valid_dataset, epochs = EPOCHS, batch_size = BATCH_SIZE, verbose = 1)

"""train the model for 3 epoches"""

XLNet_history = XLNet_model.fit(x = train_dataset, validation_data = valid_dataset, epochs = EPOCHS, verbose = 1)

"""plot the XLNet model accuracy"""

plot_accuracy("XLNet model accuracy", XLNet_history)

"""plot the XLNet model loss"""

plot_loss("XLNet model loss", XLNet_history)

"""do prediction on test dataset"""

XLNet_test_predict = XLNet_model.predict(test_dataset, verbose = 1)

XLNet_test_predict

"""we treat values greater than 0.5 as label 1, otherwise, treat it as label 0"""

XLNet_test_predict_label = (XLNet_test_predict > 0.5).astype(int).flatten()

XLNet_test_predict_label

y_test_true_label = y_test.to_numpy()

y_test_true_label

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

"""output the precision, recall, F1 score, accuracy and confusion matrix"""

print(classification_report(y_true = y_test_true_label, y_pred = XLNet_test_predict_label))
print("\n\n")
print(confusion_matrix(y_true = y_test_true_label, y_pred = XLNet_test_predict_label))
print("\n\n")
print('testing accuracy:', np.mean(y_test_true_label == XLNet_test_predict_label))

"""visualize the confusion matrix"""

XLNet_conf_mat = confusion_matrix(y_true = y_test_true_label, y_pred = XLNet_test_predict_label)
visualize_confusion_matrix(XLNet_conf_mat)

"""convert the test dataset to tf.data.Dataset"""

test_dataset_for_evaluate = (tf.data.Dataset
                 .from_tensor_slices((x_test, y_test.astype(int)))
                 .shuffle(SEED)
                 .batch(BATCH_SIZE)
                 .prefetch(AUTO))

"""output the train, validation, test accuracy and loss"""

XLNet_train_score = XLNet_model.evaluate(train_dataset, batch_size = 1)
XLNet_valid_score = XLNet_model.evaluate(valid_dataset, batch_size = 1)
XLNet_test_score = XLNet_model.evaluate(test_dataset_for_evaluate, batch_size = 1)

print("training loss:", XLNet_train_score[0], "training accuracy", XLNet_train_score[1])
print("validation loss:", XLNet_valid_score[0], "validation accuracy", XLNet_valid_score[1])
print("testing loss:", XLNet_test_score[0], "testing accuracy", XLNet_test_score[1])

"""# **Save the model and back to drive from colab**"""

from google.colab import drive
drive.mount('/content/drive')

# One-Hot Model
onehot100_model.save("/content/shared/output/onehot100_model.h5")
!cd "/content/shared/output" && cp -r onehot100_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

onehot1000_model.save("/content/shared/output/onehot1000_model.h5")
!cd "/content/shared/output" && cp -r onehot1000_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

onehot100_model_complex.save("/content/shared/output/onehot100_model_comlpex.h5")
!cd "/content/shared/output" && cp -r onehot100_model_comlpex.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

# Index Model
index_model.save("/content/shared/output/index_model.h5")
!cd "/content/shared/output" && cp -r index_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

# CNN Model
cnn_model.save("/content/shared/output/cnn_model.h5")
!cd "/content/shared/output" && cp -r cnn_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

# BERT Model
# bert_model.save("/content/shared/output/bert_model.h5")
# !cd "/content/shared/output" && cp -r bert_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

# DistilBERT Model
DistilBERT_model.save("/content/drive/MyDrive/Project/output/DistilBERT_model.h5")
# !cd "/content/shared/output" && cp -r distilbert_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

# XLNet Model
XLNet_model.save("/content/drive/MyDrive/Project/output/XLNet_model.h5")
# !cd "/content/shared/output" && cp -r xlnet_model.h5 "/content/drive/MyDrive/University/Courses/COMP 4211/Project/output"

drive.flush_and_unmount()